variables:
  AWS_DEFAULT_REGION: $AWS_DEFAULT_REGION
  AWS_ACCOUNT_ID: $AWS_ACCOUNT_ID
  IMAGE_NAME: $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/juice-shop

stages:
  - cache 
  - test
  - build
  - deploy-app
  - upload-reports
  - deploy-prod


create_cache:
  image: node:18-bullseye
  stage: cache
  script:
    - yarn install
  cache:
    key:
      files:
        - yarn.lock
    paths:
      - node_modules/
      - yarn.lock
      - .yarn
    policy: pull-push

yarn_test:
  image: node:18-bullseye
  stage: test
  script:
    - yarn install
    - yarn test
  cache:
    key:
      files:
        - yarn.lock
    paths:
      - node_modules/
      - yarn.lock
      - .yarn
    policy: pull


gitleaks:
  stage: test 
  image: 
    name: zricethezav/gitleaks
    entrypoint: [""]
  script:
    - gitleaks detect --verbose --source . -f json -r gitleaks.json
  allow_failure: true
  artifacts:
    when: always
    paths:
      - gitleaks.json

njsscan:
  stage: test
  image: python
  before_script:
    - pip3 install --upgrade njsscan
  script:
    - njsscan --exit-warning . --sarif -o njsscan.sarif
  allow_failure: true
  artifacts:
    when: always
    paths:
      - njsscan.sarif


semgrep:
  stage: test
  image: returntocorp/semgrep
  variables:
    SEMGREP_RULES: p/javascript
  script:
    - semgrep ci --json --output semgrep.json
  allow_failure: true
  artifacts:
    when: always
    paths:
      - semgrep.json

retire:
  stage: test
  image: node:18-bullseye
  before_script:
    - npm install -g retire
  script:
    - retire --path . --outputformat json --outputpath retire.json
  allow_failure: true
  artifacts:
    when: always
    paths:
      - retire.json

opa_conftest:
  stage: build
  image: docker:24
  services:
    - docker:24-dind
  script:
    - docker run --rm -v $(pwd):/project openpolicyagent/conftest test --policy opa-docker-security.rego Dockerfile -o table
  allow_failure: true   


build_image:
  stage: build
  needs: ["opa_conftest"]
  tags:
    - shell
    - ec2
  before_script:
    - aws ecr get-login-password | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com
  script:
    - docker build -t $IMAGE_NAME:$CI_COMMIT_SHA -t $IMAGE_NAME:latest .

scan_image (trivy):
  stage: build
  needs: ["build_image"]
  tags:
    - shell
    - ec2
  script:
    - trivy image -f json -o trivy.json --severity HIGH,CRITICAL --exit-code 1 $IMAGE_NAME:$CI_COMMIT_SHA
  allow_failure: true
  artifacts:
    when: always
    paths:
      - trivy.json

image_push (ecr):
  stage: build
  needs: ["scan_image (trivy)"]
  tags:
    - shell
    - ec2
  script:
    - docker push $IMAGE_NAME:$CI_COMMIT_SHA
    - docker push $IMAGE_NAME:latest

docker_image_cleanups:
  stage: build
  needs: ["image_push (ecr)"]
  tags:
    - shell
    - ec2
  script:
    - docker rmi $IMAGE_NAME:$CI_COMMIT_SHA
    - docker rmi $IMAGE_NAME:latest

deploy_app:
  stage: deploy-app
  tags:
    - shell
    - ec2
  script:
    - LOG_IN_CMD="export AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION; aws ecr get-login-password | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com"
    - COMMANDS_TO_EXECUTE="docker pull $IMAGE_NAME:latest && (docker stop juice-shop || true) && (docker rm juice-shop || true) && docker run -d --name juice-shop -p 3000:3000 $IMAGE_NAME:latest"
    - COMMAND_ID=$(aws ssm send-command --instance-ids "i-0e606fa6ca075072b" --document-name "AWS-RunShellScript" --parameters "commands=[$LOG_IN_CMD, $COMMANDS_TO_EXECUTE]" --query "Command.CommandId" --output text)
    - sleep 15
    - aws ssm get-command-invocation --command-id "$COMMAND_ID" --instance-id "i-0e606fa6ca075072b"

zap_baseline:
  stage: deploy-app
  needs: ["deploy_app"]
  image: zaproxy/zap-stable
  variables:
    ZAP_TARGET: "http://18.234.36.135:3000"
  before_script:
    - mkdir -p /zap/wrk
  script:
    - zap-baseline.py -t $ZAP_TARGET -g gen.conf -I -J baseline.json
    - cp /zap/wrk/baseline.json baseline.json
  artifacts:
    when: always
    paths:
      - baseline.json

zap_full:
  stage: deploy-app
  needs: ["deploy_app"]
  image: zaproxy/zap-stable
  variables:
    ZAP_TARGET: "http://18.234.36.135:3000"
  before_script:
    - mkdir -p /zap/wrk
  script:
    - zap-full-scan.py -t $ZAP_TARGET -g gen.conf -I -J zap.json
    - cp /zap/wrk/zap.json zap.json
  artifacts:
    when: always
    paths:
      - zap.json


upload_reports:
  stage: upload-reports
  image: python
  when: always
  before_script:
    - pip3 install requests
  script:
    - python3 upload-reports.py gitleaks.json
    - python3 upload-reports.py njsscan.sarif
    - python3 upload-reports.py semgrep.json
    - python3 upload-reports.py retire.json
    - python3 upload-reports.py trivy.json
    # - python3 upload-reports.py baseline.json
    # - python3 upload-reports.py zap.json

deploy_prod:
  stage: deploy-prod
  script:
    - echo "deploying to production environment"
  when: manual





 

